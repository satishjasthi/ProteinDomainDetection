{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes with samples between 1.5k to 10k\n",
    "#classes = [\"Lysozyme_PF01183\",\"Lysozyme_PF00182\",\"Lysozyme_PF04965\", \"Lysozyme_PF00959\",\"CHAP_PF05257\", \"SH34_PF06347\"]\n",
    "classes = [\"CHAP_PF05257\", \"SH34_PF06347\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import sys\n",
    "from pathlib import Path\n",
    "ProjectRoot = Path().cwd().parent.parent\n",
    "sys.path.append(str(ProjectRoot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from FASTA files for CHAP_PF05257\n",
      "Fetching data from FASTA files for SH34_PF06347\n",
      "number of seqs below 1000: 94\n",
      "Dropped 123 number of duplicates based on sequences\n",
      "Class distribution: \n",
      "\n",
      "PF05257    3425\n",
      "PF06347    1648\n",
      "Name: Class, dtype: int64\n",
      "Genreating  images\n",
      "Saving annotations\n"
     ]
    }
   ],
   "source": [
    "from src.data.modelData import ObjectDetection\n",
    "! trash-put /home/satish27may/ProteinDomainDetection/data/PfamData/images_224/\n",
    "! trash-put /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/\n",
    "data_handler = ObjectDetection(class_names=classes, img_dim=224)\n",
    "data_handler.create_coco_data(augment_data=False, num_augs=1000, img_h=224, img_w=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset’: File exists\n",
      "trash-put: cannot trash non existent '/home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/images_224'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:29<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/25 13:11:02 d2.data.datasets.coco]: \u001b[0mLoaded 3552 images in COCO format from /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/img_D0RQI1_9PROT_PF06347_SH3_4.png', 'height': 224, 'width': 1000, 'image_id': 5200, 'annotations': [{'iscrowd': 0, 'bbox': [25, 0, 56, 224], 'category_id': 1, 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1500x336 at 0x7F5D9A637F90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/img_A0A395NMJ3_TRIAR_PF05257_CHAP.png', 'height': 224, 'width': 1000, 'image_id': 2543, 'annotations': [{'iscrowd': 0, 'bbox': [119, 0, 90, 224], 'category_id': 0, 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1500x336 at 0x7F5D99825AD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/img_A0A430AGL2_9ENTE_PF05257_CHAP.png', 'height': 224, 'width': 1000, 'image_id': 1085, 'annotations': [{'iscrowd': 0, 'bbox': [176, 0, 92, 224], 'category_id': 0, 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1500x336 at 0x7F5D99825A50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "# images used should be at 224x1000 dim\n",
    "register_coco_instances(\"ballon_train\", {}, \"/home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/train.json\", \"/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/\")\n",
    "register_coco_instances(\"ballon_val\", {}, \"/home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/val.json\", \"/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/\")\n",
    "# register_coco_instances(\"ballon_test\", {}, \"/home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224//test.json\", \"/home/satish27may/ProteinDomainDetection/data/PfamData/images_224/\")\n",
    "balloon_metadata = MetadataCatalog.get(\"balloon_train\")\n",
    "\n",
    "! mkdir /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset\n",
    "! trash-put /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/class1\n",
    "! trash-put /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/images_224\n",
    "! mkdir /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/class1\n",
    "! cp  -r /home/satish27may/ProteinDomainDetection/data/PfamData/images_224/  /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/class1/\n",
    "#! mv /home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset/images_224 /home/satish27may/DetectoRS_mmdetect/mmdetection/data/torch_dataset/class1\n",
    "def get_mean_std(loader):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(loader):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "custom_dataset = datasets.ImageFolder('/home/satish27may/ProteinDomainDetection/data/PfamData/torch_dataset', transform=transforms.ToTensor())\n",
    "custom_data_loader = DataLoader(dataset=custom_dataset,batch_size=128)\n",
    "data_mean, data_std = get_mean_std(custom_data_loader)\n",
    "\n",
    "data_mean = data_mean.numpy().tolist()\n",
    "data_std = data_std.numpy().tolist()\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"ballon_train\")\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=1.5)\n",
    "    bbox = d['annotations'][0]['bbox']\n",
    "    out = visualizer.draw_box((bbox[0],bbox[1],bbox[0]+bbox[2],bbox[1]+bbox[3]), edge_color='red', line_style='-')\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! trash-put /home/satish27may/ProteinDomainDetection/models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/25 14:51:04 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[11/25 14:51:04 d2.data.datasets.coco]: \u001b[0mLoaded 3552 images in COCO format from /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/train.json\n",
      "\u001b[32m[11/25 14:51:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3552 images left.\n",
      "\u001b[32m[11/25 14:51:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(horizontal=False, vertical=True)]\n",
      "\u001b[32m[11/25 14:51:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/25 14:51:04 d2.data.common]: \u001b[0mSerializing 3552 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/25 14:51:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (18, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (18,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/25 14:51:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n",
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/fvcore/transforms/transform.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.ascontiguousarray(img))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/25 14:51:19 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 19  total_loss: 0.6909  loss_cls: 0.5069  loss_box_reg: 0.1692  time: 0.7011  data_time: 0.0224  lr: 1.991e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:51:33 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 39  total_loss: 1.366  loss_cls: 1.044  loss_box_reg: 0.2928  time: 0.6998  data_time: 0.0050  lr: 3.9364e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:51:47 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 59  total_loss: 0.8596  loss_cls: 0.6254  loss_box_reg: 0.2612  time: 0.6984  data_time: 0.0047  lr: 5.7905e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:52:00 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 79  total_loss: 0.6292  loss_cls: 0.3864  loss_box_reg: 0.2306  time: 0.6973  data_time: 0.0050  lr: 7.5098e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:52:14 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 99  total_loss: 0.5621  loss_cls: 0.3626  loss_box_reg: 0.1852  time: 0.6966  data_time: 0.0049  lr: 9.0545e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:52:28 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 119  total_loss: 0.5617  loss_cls: 0.3415  loss_box_reg: 0.1977  time: 0.6962  data_time: 0.0048  lr: 0.00010389  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:52:42 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 139  total_loss: 0.6648  loss_cls: 0.4354  loss_box_reg: 0.218  time: 0.6958  data_time: 0.0047  lr: 0.00011484  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:52:56 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 159  total_loss: 0.6664  loss_cls: 0.4339  loss_box_reg: 0.1945  time: 0.6956  data_time: 0.0050  lr: 0.00012317  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:53:10 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 179  total_loss: 0.645  loss_cls: 0.4505  loss_box_reg: 0.1918  time: 0.6955  data_time: 0.0048  lr: 0.0001287  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:53:24 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 199  total_loss: 0.5055  loss_cls: 0.3303  loss_box_reg: 0.2002  time: 0.6954  data_time: 0.0048  lr: 0.00013137  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:53:38 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 219  total_loss: 0.4518  loss_cls: 0.3109  loss_box_reg: 0.1741  time: 0.6952  data_time: 0.0048  lr: 0.00013116  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:53:52 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 239  total_loss: 0.5226  loss_cls: 0.32  loss_box_reg: 0.1692  time: 0.6950  data_time: 0.0047  lr: 0.00012816  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:54:05 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 259  total_loss: 0.5016  loss_cls: 0.3285  loss_box_reg: 0.1818  time: 0.6949  data_time: 0.0049  lr: 0.00012253  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:54:19 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 279  total_loss: 0.448  loss_cls: 0.3003  loss_box_reg: 0.1624  time: 0.6947  data_time: 0.0048  lr: 0.00011452  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:54:33 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 299  total_loss: 0.4377  loss_cls: 0.2855  loss_box_reg: 0.1582  time: 0.6946  data_time: 0.0050  lr: 0.00010444  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:54:47 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 319  total_loss: 0.4827  loss_cls: 0.3131  loss_box_reg: 0.1804  time: 0.6945  data_time: 0.0050  lr: 9.2694e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:55:01 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 339  total_loss: 0.438  loss_cls: 0.2648  loss_box_reg: 0.1705  time: 0.6945  data_time: 0.0048  lr: 7.9734e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:55:15 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 359  total_loss: 0.4431  loss_cls: 0.2801  loss_box_reg: 0.1783  time: 0.6943  data_time: 0.0046  lr: 6.6071e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:55:29 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 379  total_loss: 0.4  loss_cls: 0.264  loss_box_reg: 0.1563  time: 0.6943  data_time: 0.0050  lr: 5.2264e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:55:43 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 399  total_loss: 0.4674  loss_cls: 0.3055  loss_box_reg: 0.1532  time: 0.6942  data_time: 0.0048  lr: 3.89e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:55:56 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 419  total_loss: 0.4353  loss_cls: 0.2496  loss_box_reg: 0.1631  time: 0.6941  data_time: 0.0049  lr: 2.6588e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:56:10 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 439  total_loss: 0.4042  loss_cls: 0.2567  loss_box_reg: 0.1623  time: 0.6941  data_time: 0.0051  lr: 1.5946e-05  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:56:24 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 459  total_loss: 0.3953  loss_cls: 0.238  loss_box_reg: 0.1588  time: 0.6940  data_time: 0.0053  lr: 7.5821e-06  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:56:38 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 479  total_loss: 0.4352  loss_cls: 0.2786  loss_box_reg: 0.1534  time: 0.6940  data_time: 0.0050  lr: 2.0841e-06  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:56:53 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.417  loss_cls: 0.268  loss_box_reg: 0.1678  time: 0.6939  data_time: 0.0051  lr: 4.9299e-09  max_mem: 2292M\n",
      "\u001b[32m[11/25 14:56:53 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:05:45 (0.6939 s / it)\n",
      "\u001b[32m[11/25 14:56:53 d2.engine.hooks]: \u001b[0mTotal training time: 0:05:46 (0:00:01 on hooks)\n",
      "\u001b[32m[11/25 14:56:53 d2.data.datasets.coco]: \u001b[0mLoaded 1521 images in COCO format from /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/val.json\n",
      "\u001b[32m[11/25 14:56:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/25 14:56:53 d2.data.common]: \u001b[0mSerializing 1521 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/25 14:56:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/25 14:56:53 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "img_h, img_w = 224, 1000\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"ballon_train\",)\n",
    "cfg.DATASETS.TEST = (\"ballon_val\",)\n",
    "#cfg.MODEL.PIXEL_MEAN = data_mean\n",
    "#cfg.MODEL.PIXEL_STD = data_std\n",
    "cfg.INPUT.RANDOM_FLIP = \"vertical\"\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
    "\n",
    "\n",
    "cfg.TEST.AUG.FLIP = False\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 1e-3  # pick a good LR\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "#cfg.MODEL.RETINANET.IOU_THRESHOLDS = [0.4, 0.5]\n",
    "cfg.SOLVER.MAX_ITER = 500 \n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = len(data_handler.class_names)\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(data_handler.class_names)\n",
    "\n",
    "cfg.OUTPUT_DIR = '/home/satish27may/ProteinDomainDetection/models'\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/25 15:17:36 d2.data.datasets.coco]: \u001b[0mLoaded 1521 images in COCO format from /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/val.json\n",
      "\u001b[32m[11/25 15:17:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/25 15:17:36 d2.data.common]: \u001b[0mSerializing 1521 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/25 15:17:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[11/25 15:17:36 d2.data.datasets.coco]: \u001b[0mLoaded 1521 images in COCO format from /home/satish27may/ProteinDomainDetection/data/PfamData/annotations_224/val.json\n",
      "\u001b[32m[11/25 15:17:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/25 15:17:36 d2.data.common]: \u001b[0mSerializing 1521 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/25 15:17:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[11/25 15:17:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 1521 images\n",
      "\u001b[32m[11/25 15:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/1521. 0.1821 s / img. ETA=0:04:36\n",
      "\u001b[32m[11/25 15:17:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/1521. 0.1825 s / img. ETA=0:04:32\n",
      "\u001b[32m[11/25 15:17:49 d2.evaluation.evaluator]: \u001b[0mInference done 67/1521. 0.1825 s / img. ETA=0:04:27\n",
      "\u001b[32m[11/25 15:17:54 d2.evaluation.evaluator]: \u001b[0mInference done 95/1521. 0.1824 s / img. ETA=0:04:22\n",
      "\u001b[32m[11/25 15:17:59 d2.evaluation.evaluator]: \u001b[0mInference done 123/1521. 0.1824 s / img. ETA=0:04:17\n",
      "\u001b[32m[11/25 15:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 151/1521. 0.1821 s / img. ETA=0:04:11\n",
      "\u001b[32m[11/25 15:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 179/1521. 0.1821 s / img. ETA=0:04:06\n",
      "\u001b[32m[11/25 15:18:15 d2.evaluation.evaluator]: \u001b[0mInference done 207/1521. 0.1821 s / img. ETA=0:04:01\n",
      "\u001b[32m[11/25 15:18:20 d2.evaluation.evaluator]: \u001b[0mInference done 235/1521. 0.1820 s / img. ETA=0:03:56\n",
      "\u001b[32m[11/25 15:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 263/1521. 0.1820 s / img. ETA=0:03:51\n",
      "\u001b[32m[11/25 15:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 291/1521. 0.1820 s / img. ETA=0:03:45\n",
      "\u001b[32m[11/25 15:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 319/1521. 0.1819 s / img. ETA=0:03:40\n",
      "\u001b[32m[11/25 15:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 347/1521. 0.1818 s / img. ETA=0:03:35\n",
      "\u001b[32m[11/25 15:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 375/1521. 0.1817 s / img. ETA=0:03:30\n",
      "\u001b[32m[11/25 15:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 403/1521. 0.1817 s / img. ETA=0:03:25\n",
      "\u001b[32m[11/25 15:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 431/1521. 0.1816 s / img. ETA=0:03:19\n",
      "\u001b[32m[11/25 15:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 459/1521. 0.1815 s / img. ETA=0:03:14\n",
      "\u001b[32m[11/25 15:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 487/1521. 0.1815 s / img. ETA=0:03:09\n",
      "\u001b[32m[11/25 15:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 515/1521. 0.1815 s / img. ETA=0:03:04\n",
      "\u001b[32m[11/25 15:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 543/1521. 0.1815 s / img. ETA=0:02:59\n",
      "\u001b[32m[11/25 15:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 571/1521. 0.1814 s / img. ETA=0:02:53\n",
      "\u001b[32m[11/25 15:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 599/1521. 0.1814 s / img. ETA=0:02:48\n",
      "\u001b[32m[11/25 15:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 627/1521. 0.1813 s / img. ETA=0:02:43\n",
      "\u001b[32m[11/25 15:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 655/1521. 0.1813 s / img. ETA=0:02:38\n",
      "\u001b[32m[11/25 15:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 683/1521. 0.1813 s / img. ETA=0:02:33\n",
      "\u001b[32m[11/25 15:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 711/1521. 0.1813 s / img. ETA=0:02:28\n",
      "\u001b[32m[11/25 15:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 739/1521. 0.1813 s / img. ETA=0:02:23\n",
      "\u001b[32m[11/25 15:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 767/1521. 0.1812 s / img. ETA=0:02:17\n",
      "\u001b[32m[11/25 15:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 795/1521. 0.1812 s / img. ETA=0:02:12\n",
      "\u001b[32m[11/25 15:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 823/1521. 0.1812 s / img. ETA=0:02:07\n",
      "\u001b[32m[11/25 15:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 851/1521. 0.1812 s / img. ETA=0:02:02\n",
      "\u001b[32m[11/25 15:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 879/1521. 0.1812 s / img. ETA=0:01:57\n",
      "\u001b[32m[11/25 15:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 907/1521. 0.1812 s / img. ETA=0:01:52\n",
      "\u001b[32m[11/25 15:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 935/1521. 0.1811 s / img. ETA=0:01:47\n",
      "\u001b[32m[11/25 15:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 963/1521. 0.1811 s / img. ETA=0:01:42\n",
      "\u001b[32m[11/25 15:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 991/1521. 0.1811 s / img. ETA=0:01:36\n",
      "\u001b[32m[11/25 15:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 1019/1521. 0.1811 s / img. ETA=0:01:31\n",
      "\u001b[32m[11/25 15:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 1047/1521. 0.1811 s / img. ETA=0:01:26\n",
      "\u001b[32m[11/25 15:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 1075/1521. 0.1811 s / img. ETA=0:01:21\n",
      "\u001b[32m[11/25 15:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 1103/1521. 0.1811 s / img. ETA=0:01:16\n",
      "\u001b[32m[11/25 15:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 1131/1521. 0.1810 s / img. ETA=0:01:11\n",
      "\u001b[32m[11/25 15:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 1159/1521. 0.1811 s / img. ETA=0:01:06\n",
      "\u001b[32m[11/25 15:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 1187/1521. 0.1810 s / img. ETA=0:01:01\n",
      "\u001b[32m[11/25 15:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 1215/1521. 0.1810 s / img. ETA=0:00:55\n",
      "\u001b[32m[11/25 15:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 1243/1521. 0.1810 s / img. ETA=0:00:50\n",
      "\u001b[32m[11/25 15:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 1271/1521. 0.1810 s / img. ETA=0:00:45\n",
      "\u001b[32m[11/25 15:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 1299/1521. 0.1810 s / img. ETA=0:00:40\n",
      "\u001b[32m[11/25 15:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 1327/1521. 0.1809 s / img. ETA=0:00:35\n",
      "\u001b[32m[11/25 15:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 1355/1521. 0.1809 s / img. ETA=0:00:30\n",
      "\u001b[32m[11/25 15:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 1383/1521. 0.1809 s / img. ETA=0:00:25\n",
      "\u001b[32m[11/25 15:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 1411/1521. 0.1809 s / img. ETA=0:00:20\n",
      "\u001b[32m[11/25 15:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 1439/1521. 0.1809 s / img. ETA=0:00:14\n",
      "\u001b[32m[11/25 15:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 1467/1521. 0.1809 s / img. ETA=0:00:09\n",
      "\u001b[32m[11/25 15:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 1495/1521. 0.1809 s / img. ETA=0:00:04\n",
      "\u001b[32m[11/25 15:22:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:36.899448 (0.182651 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/25 15:22:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:34 (0.180902 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/25 15:22:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/25 15:22:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[11/25 15:22:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.59 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 16.721 | 28.539 | 16.424 |  nan  | 0.195 | 16.730 |\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP    |\n",
      "|:-----------|:-------|:-----------|:------|\n",
      "| PF05257    | 29.976 | PF06347    | 3.467 |\n",
      "\u001b[32m[11/25 15:22:16 d2.engine.defaults]: \u001b[0mEvaluation results for ballon_val in csv format:\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/25 15:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: 16.7214,28.5394,16.4239,nan,0.1951,16.7303\n",
      "OrderedDict([('bbox', {'AP': 16.721436267241344, 'AP50': 28.53942742631857, 'AP75': 16.4238643153885, 'APs': nan, 'APm': 0.195052472280195, 'APl': 16.730296101946816, 'AP-PF05257': 29.97620409165634, 'AP-PF06347': 3.466668442826347})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"ballon_val\", (\"bbox\",), False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"ballon_val\")\n",
    "print(trainer.test(cfg, trainer.model, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCOeval_opt.accumulate() finished in 0.09 seconds.\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
    "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.502\n",
    "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.418\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.716\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
    "[11/23 15:01:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
    "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
    "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
    "| 32.324 | 50.211 | 35.325 |  nan  | 0.000 | 32.349 |\n",
    "[11/23 15:01:16 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
    "[11/23 15:01:16 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
    "| category   | AP     | category   | AP     |\n",
    "|:-----------|:-------|:-----------|:-------|\n",
    "| PF05257    | 41.624 | PF06347    | 23.025 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "COCOeval_opt.accumulate() finished in 0.62 seconds.\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
    "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
    "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
    "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.581\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
    "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
    "[11/23 10:26:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
    "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
    "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
    "| 34.336 | 45.023 | 38.327 |  nan  | 20.099 | 34.352 |\n",
    "[11/23 10:26:47 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
    "[11/23 10:26:47 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
    "| category   | AP     | category   | AP     | category   | AP     |\n",
    "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
    "| PF01183    | 54.320 | PF05257    | 11.621 | PF00959    | 28.577 |\n",
    "| PF00182    | 35.231 | PF04965    | 70.866 | PF06347    | 5.398  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

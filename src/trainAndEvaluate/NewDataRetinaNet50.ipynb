{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProjectRoot: /home/satish27may/ProteinDomainDetection\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model to train protein sequences of len btw 0-300 and samples size 1k-10k\n",
    "\"\"\"\n",
    "import sys, random , re, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "ProjectRoot = Path('/home/satish27may/ProteinDomainDetection/')\n",
    "print(f\"ProjectRoot: {ProjectRoot}\")\n",
    "sys.path.append(str(ProjectRoot))\n",
    "\n",
    "from src.data.modelData import ObjectDetection, create_protein_seq_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2663 number of duplicates based on sequences\n",
      "Fetching data with sequence len in btw (0, 300) and class with num samples btw (1000, 10000)\n",
      "Bucket class distribution: PF01551    9121\n",
      "PF01435    7878\n",
      "PF01510    6831\n",
      "PF00814    6775\n",
      "PF00722    6269\n",
      "PF08239    4598\n",
      "PF01520    4174\n",
      "PF04965    3157\n",
      "PF01183    3060\n",
      "PF00959    2279\n",
      "PF00704    2076\n",
      "PF00182    1874\n",
      "PF05257    1638\n",
      "PF06347    1388\n",
      "PF00246    1355\n",
      "PF05838    1095\n",
      "Name: Class, dtype: int64\n",
      "  Sequences lens: min=26, max = 299\n",
      "Genreating  images of dim 224x300 data bucket with sequence len in btw (0, 300) and class with num samples btw (1000, 10000)\n",
      "Selected 4 classes:\n",
      "['PF08239' 'PF01510' 'PF00246' 'PF06347']\n"
     ]
    }
   ],
   "source": [
    "# create bucket data\n",
    "seq_len_bucket = (0, 300)\n",
    "num_sample_bucket = (1000,10000)\n",
    "img_h, img_w = 224, seq_len_bucket[1]\n",
    "config_name = f\"seq_len_{seq_len_bucket[0]}-{seq_len_bucket[1]}_and_num_samples_{num_sample_bucket[0]}-{num_sample_bucket[1]}\"\n",
    "\n",
    "# os.system(f\"trash-put {str(ProjectRoot/f'data/PfamData/{config_name}_images')}\")\n",
    "os.system(f\"trash-put {str(ProjectRoot/f'models/{config_name}_model')}\")\n",
    "\n",
    "# create model dir to save checkpoints\n",
    "all_models_dir = ProjectRoot/'models'\n",
    "if not all_models_dir.exists():\n",
    "    all_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "model_dir = ProjectRoot/f'models/{config_name}_model'\n",
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# # log to log file\n",
    "# log_file = model_dir/'logs.txt'\n",
    "# sys.stdout = open(str(log_file), 'w')\n",
    "    \n",
    "# create all classes data from pfam fasta data\n",
    "all_classes = ['Lysozyme-PF03245',\n",
    "'Lysozyme-PF16754',\n",
    "'Lysozyme-PF11860',\n",
    "'Lysozyme-PF13702',\n",
    "'Lysozyme-PF00959',\n",
    "'Lysozyme-PF00182',\n",
    "'Lysozyme-PF00704',\n",
    "'Lysozyme-PF01374',\n",
    "'Lysozyme-PF05838',\n",
    "'Lysozyme-PF18013',\n",
    "'Lysozyme-PF04965',\n",
    "'Lysozyme-PF01183',\n",
    "'Lysozyme-PF00722',\n",
    "'peptidase-PF05193',\n",
    "'peptidase-PF01551',\n",
    "'peptidase-PF00675',\n",
    "'peptidase-PF01435',\n",
    "'peptidase-PF01433',\n",
    "'peptidase-PF10502',\n",
    "'peptidase-PF00246',\n",
    "'peptidase-PF03572',\n",
    "'peptidase-PF00814',\n",
    "'peptidase-PF17900',\n",
    "'Amidase_2-PF01510',\n",
    "'Amidase_3-PF01520',\n",
    "'CHAP-PF05257',\n",
    "'SH3_4-PF06347',\n",
    "'SH3_3-PF08239',\n",
    "'SH3_5-PF08460',\n",
    "'LysM-PF01476']\n",
    "data_handler = ObjectDetection(class_names=all_classes)\n",
    "protein_domain_data = data_handler.create_protein_domain_df()\n",
    "\n",
    "# create data df for choosen config\n",
    "bucket_df = data_handler.get_bucketised_data(protein_domain_data, seq_len_bucket, num_sample_bucket)\n",
    "class_freq_map = dict(bucket_df['Class'].value_counts())\n",
    "classes = [cls for cls in list(bucket_df['Class'].unique()) if class_freq_map[cls]>50]\n",
    "bucket_df = bucket_df[bucket_df['Class'].isin(classes)]\n",
    "# select sub set classes !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "bucket_df = bucket_df[bucket_df['Class'].isin(['PF08239', 'PF06347', 'PF00246', 'PF01510'])]\n",
    "classes= list(bucket_df['Class'].unique() )\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "bucket_df.to_csv(ProjectRoot/f\"data/PfamData/seq_len_{'-'.join([str(x) for x in seq_len_bucket])}_and_num_samples_{'-'.join([str(x) for x in num_sample_bucket])}_data.csv\",index=False)\n",
    "\n",
    "\n",
    "# create image data for choosen config\n",
    "data_handler.create_bucket_sequence2histogram(bucket_df, seq_len_bucket, num_sample_bucket)\n",
    "\n",
    "# print config data summary\n",
    "images_dir = ProjectRoot/f\"data/PfamData/{config_name}_images\"\n",
    "model_data =  pd.read_csv(ProjectRoot/f\"data/PfamData/{config_name}_data.csv\")\n",
    "print(f\"Selected {model_data['Class'].nunique()} classes:\\n{model_data['Class'].unique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected: ['PF08239' 'PF01510' 'PF00246' 'PF06347']\n",
      "SuperClasses selected: ['SH3_3' 'Amidase_2' 'peptidase' 'SH3_4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [00:00<00:00, 11896.88it/s]\n",
      "  0%|          | 0/4251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes selected: ['PF08239' 'PF01510' 'PF00246' 'PF06347']\n",
      "SuperClasses selected: ['SH3_3' 'Amidase_2' 'peptidase' 'SH3_4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4251/4251 [00:00<00:00, 10590.10it/s]\n"
     ]
    }
   ],
   "source": [
    "###############################################Create Model Data##############################################################################\n",
    "def create_train_valid_test_data(data_df):\n",
    "    train_dfs,valid_dfs = [],[],\n",
    "    for class_name in data_df['Class'].unique():\n",
    "        class_df = data_df[data_df['Class']==class_name].sample(frac=1)\n",
    "        num_samples = class_df.shape[0]\n",
    "        num_train_samples = int(round(num_samples*0.7))\n",
    "        train_dfs.append(class_df.iloc[:num_train_samples,:])\n",
    "        valid_dfs.append(class_df.iloc[num_train_samples:,:])\n",
    "    return pd.concat(train_dfs,axis='rows').sample(frac=1), pd.concat(valid_dfs,axis='rows').sample(frac=1)\n",
    "    \n",
    "def create_dataset(model_data, img_h, img_w, mode, classes, aug_data):\n",
    "    model_data = model_data[model_data['Class'].isin([x.split('-')[-1] for x in classes])]\n",
    "    print(f\"Classes selected: {model_data['Class'].unique()}\")\n",
    "    print(f\"SuperClasses selected: {model_data['SuperClass'].unique()}\")\n",
    "    model_data = model_data.reset_index(drop=True)\n",
    "    model_data['dom_pos'] = model_data['dom_pos'].apply(lambda x: [int(y) for y in x.replace('[','').replace(']','').split(',')])\n",
    "    C2I = {class_name:index for index, class_name in enumerate(model_data['Class'].unique())}\n",
    "    train_dicts_list = []\n",
    "    valid_dicts_list = []\n",
    "    train, valid = create_train_valid_test_data(model_data)\n",
    "    train = train.reset_index(drop=True)\n",
    "    valid = valid.reset_index(drop=True)\n",
    "    if mode=='train':\n",
    "        for index in tqdm(range(train.shape[0])):\n",
    "            x1,x2 = train['dom_pos'][index]\n",
    "            train_dicts_list.append({'file_name':train['img_pth'][index],\n",
    "                               'height':img_h,\n",
    "                               'width': img_w,\n",
    "                               'image_id': index,\n",
    "                               'annotations':[{'bbox':[x1, 0, x2, img_h],\n",
    "                                               'bbox_mode':BoxMode.XYXY_ABS,\n",
    "                                               'category_id':  C2I[train['Class'][index]],\n",
    "                                              }]\n",
    "                              })\n",
    "    if mode=='valid':\n",
    "        for index in tqdm(range(valid.shape[0])):\n",
    "            x1,x2 = valid['dom_pos'][index]\n",
    "            valid_dicts_list.append({'file_name':valid['img_pth'][index],\n",
    "                               'height':img_h,\n",
    "                               'width': img_w,\n",
    "                               'image_id': index,\n",
    "                               'annotations':[{'bbox':[x1, 0, x2, img_h],\n",
    "                                               'bbox_mode':BoxMode.XYXY_ABS,\n",
    "                                               'category_id':  C2I[valid['Class'][index]],\n",
    "                                              }]\n",
    "                              })\n",
    "    if mode=='train':return train_dicts_list\n",
    "    elif mode=='valid': return valid_dicts_list\n",
    "\n",
    "# create train and valid data\n",
    "train_list = create_dataset(model_data, img_h=img_h, img_w=img_w, mode='train', classes=classes, aug_data=False)\n",
    "valid_list = create_dataset(model_data, img_h=img_h, img_w=img_w, mode='valid', classes=classes, aug_data=False)\n",
    "def get_train_data():\n",
    "    return train_list\n",
    "\n",
    "def get_valid_data():\n",
    "    return valid_list\n",
    "\n",
    "\n",
    "# add custom dataset to detectron 2 pipline\n",
    "DatasetCatalog.register(\"train\", get_train_data)\n",
    "DatasetCatalog.register(\"valid\", get_valid_data)\n",
    "\n",
    "train_meta_data = MetadataCatalog.get(\"train\").set(thing_classes = classes)\n",
    "valid_meta_data = MetadataCatalog.get(\"valid\").set(thing_classes = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_E0SMW1_DICD3_PF01510_Amidase_2.png', 'height': 224, 'width': 300, 'image_id': 4722, 'annotations': [{'bbox': [43, 0, 183, 224], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 1}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=145x112 at 0x7FC2B5F73A10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_A0A1V2GTE2_9PROT_PF06347_SH3_4.png', 'height': 224, 'width': 300, 'image_id': 5293, 'annotations': [{'bbox': [94, 0, 144, 224], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 3}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEwAAABwCAIAAAA7TQGqAAAEuUlEQVR4nO2cbWxTVRiA3957uzEdm83KNt2Hc34QMZHsB1lEoWR/iMsiSzYygkZkS5pghEAiaozcyFQ+DH+Mk8UAhhnSRF1cloWAfASYxpkwiVnHmB8T2EdtS0c7uCNtt97648jNtezent7erren58my3J69fc95znvOuXdNNpMgCG63GwxAU4MNonO/njvy1/VJlmWv3/xnz4FjwVAYtaCYXR90uDzTrZvrG+tfEiPRgx2OgctXAWDpw3n87jeeeqIsGo1++OnxoZGxN7c2rnuxRgTmdmCWS6vXAoTC4Rb7PgDY935r8yt1J7rPSy2I6qrK9XW1Ta0fLSsq/PLQzg2v86IYfWf7qz9fvrZ771GOY/NycwBMXd+cPnz8ZISzbG5czaRPR5EIZ4lwlsGrU+UVFRHOAmBCLehr7ZraU5eGg9GlEz5x3OVf8dzzeQWlNSuXd58ZiXCWEBQEQkvAxM3eC6JseUvMhqskgmWYNauW/zT4BwDk5pi/69wOAFNu/869J0qKCodGx1GYxzdTbC0Ihub8gdmP325+pvrRkT+nDnb2hQUAgLdaNzSsf+HubNBwkrk5OUjpivPG96cHASAUntu47XOVt7As8+zTj+0/3OccnXh3W0Nby7rOY98CQMdXvZ993d+2yWY4yVA4rK7kmZ4pWVaIrkushV7fHY9vxnPrjnN0AgDO/jjc1mKTx588/5sR96Q6FweuvWxbaTazZaWWx8uszt8npv2C+1agqtwKALU1T46NewGgsqwYxdetXmG4SsZl7Kb3h/6h3iO75iPiJx29ohgFgP1f9B14r8XMsZPu23sOdQPADntzVUWpGGVc3oDJaPdJMJkjnCXJVOy8X54q85arBvSX5Hle5WWSuFwunEZ/ICB/aaA9eaZrBxeanM8tv1vUpBTD83x7e3vcxnNHX9tYv0pKldnLFXOZZLYkJv9J8jz/4KygloQ2VdxgKQBn68pHpZQZZ3i4ldT3/Ehpj9Ibe3p60EU2LVcllNbwgz+KWVo4Sz0mFZp4afoTGhUo7DgErSQpxEry98FPgRksD4t7ZuoFyp+VlSSSxCQX/26pCxof0FOxaZNBpQue5+lyJQUqaUg03GMzT1IDDCjMjdK1HF2OTXmSCxcvLBiQZEdZU0nioZKkQCVJgUqSApUkhayQNAmCYLfb0z0MAIC1lX9bHxJ89/L7x6v1TZUVlaSSpEAlSYFKkgKVJAUqSQpUkhSoJClQSVKgkqRAJUmBSpIClQRwOBxKLTE/kr9UilFPNTDwi/Q90VGp9xUr6bhP3J5wsiuFYc5C8qD8ei7XVI9YM1m/J1Fl9F26mrMpvREnIWmVXNCZgSSOgUXbhEl2lKpKpuUQUuqUtOW6IFTy/yT6nKEZnKeRhPrVp5IJ+S/+dmWkjvH71jxKlfsezowk1K/TOSxda/y7kFQ83CaDShcOh4MePJrAXIe6JFdqjPl9jVaSFKgkKeBKLv4dPPm7sXT8ZHYlMScisyUxoZKkQCUNiYZPpDJPUgOJSRr2M3J1aCVJwSQIQn5+frqHAQCwxQZVxXDDC12XdE6VFZWkkqRAJUmBSpIClSQFKkkKWSFpoP+5jCh9BLbY4ofFTSLnX3E6GDot3WNEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=76x112 at 0x7FC2A7611090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_I4ZC34_9BACT_PF01510_Amidase_2.png', 'height': 224, 'width': 300, 'image_id': 9743, 'annotations': [{'bbox': [0, 0, 140, 224], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 1}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE4AAABwCAIAAAA/uNGXAAAFM0lEQVR4nO2bbWhbVRjHn/uSJWnSNCFd+k5htDqb6XTihw2mMB2jDuqHOjZ1KCIq6BAZgvRLBtJ2DsaYMkFRQS1EdKtJN2QTldTZaWVjbu1WWzo7164NqdqsTdomS3KvH65Ls+Tm5ua+pZx7fh9Kcs5zXv73/5yXGyhR3eS+78jl2Mw4QVLx0MTNng42EXO/NxybGQcAAJj8eF9ibqZy+8uOze3ApIInuqOj5wCg7tnO8g2PJSNz1w4+xUW6Wl93bHk6GQ0DQOjU0ejIWaqsouGlo+bG+2/95gse7+LCTA0t9Xu7CYMpevVssLcbAHZ39YCi1Nvo9vXWrEIaAJhEfPJwOwDU7D209tE94f7P2TslHJbaJvvDT954t42ucNW/9sn1rp3AMpHz/vlz3prnDhooggsjSQj/9EU48Bn31UARBJuYO31sTU2TsaY5HVa3+0DoqwOxG0N1r35o37B18Y+BehutlMi/l1LxJMtbRQMAAeAwkQAAUxet1feAiYR0CQAAlD20LTl82m5IwVKQnZta27wxOXkZZn4nHbUUsRJppgkmRUBGQ4A4BC+ZahtpiuDCyPJKg9lqDl0xm8jUpVPOB59Yc/2XXAck0zsavbmQzCv1f0jKeO/W22MDAEAYjI43jgMAE56e73mTtFUlJoe4KGY+RNlc/J0BlG15xrypLTF9NfrtYXZ5ITeAtLmY+VC6K9LmkiqqaGjIEJb46+LyhW8AgE3Ew+/vKravpcGvF3/8CIC1bN9n3flW5IRH8enKgQYRwpiFEGWv4j6TFVWphVneMDb6L/dh+Xyv/YVjebqaJStWumLydKUGZOEQgPhIv3FjK1AG0lFHOxuTU8P8fZVXch+M7seToWu8MUzkHzYepRseAADTprb4SEDStKUgautLzf4ZH/rOub+PZZKRvi5gGQCw7TlkWPcIabE7O35Y/P6D2AWftXU/XbseWDYVno743uHaOt8+QxitQBmM7m23Pn0lNTsR8XfadnUSBlN8bOD22M8qirsborrJTQHrMImyVyX8fr9SXXE7MO+5WkqFGqMjqfSLR3rtZEzBQ3zVoiNXsVQUwVJRpAipHk/29T23pKjmGqOFqyUXyYETGEWEpGYmnviFqni6Cgxd1FjYVRS5S6rM46QgAjkveSDx66gErgqryqrlvop/ED6fL18VKVxdEnhNlmB7VhNSckfyp6Ixet2W0EYtqasknzOngV1FER6pAge6Zvde4WlIQ9+ucuR7rRHzpLXfkzJHDPQHeKuwqyhSWKpKrzueO0hoWHAOvLd6ia4Wu3oFmsvpR2QPXHm2VDnjifFfjRwR47PH49HlWl0lt1YBZM6Q6Dg5Guj7ct3yuFITKi0T5uYoZbWmormKdJnAyIOlogiWiiJYKopgqSiCpaIIlooiWCqKYKkogqWiCJaKIliqQni93oIl6o2VBXYVRfQnVfwSyheZVa7emizIleGV/yTOnIZcVzWWlDlcsUPrL4H1AJaKIoWlqnfj8Xq9Wu5q2FUUWZFaMJfEZHLuuZf+KyZXhWNkZrtEV+Uc5fmayF+3wjc5XSYw8mRLlZNF0tqql7dZMTp2FWF4pAocDMWWy0Hxu5S+XdUGyY5l3kzyMfjrYG4hdhVFtJBawp/UMsGuAkChO71mB4/A0EWNhV1Vk6JeSsUcLZnwHjMceaXKeSPVfh8SGDFdRYPgkygJSr24ZzXR0VqFjpOj0LKj1LNQjpYdsPl5XkU6chVLRREsFUWwVBTBUlFER1JpAACLA527ocWRr+Y/yIsoGI/65RcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=78x112 at 0x7FC2B5DCAC90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in random.sample(train_list, 3):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_meta_data, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!trash-put /home/satish27may/ProteinDomainDetection/models/seq_len_0-300_and_num_samples_1000-10000_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/06 05:18:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/06 05:18:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 9921 images left.\n",
      "\u001b[32m[12/06 05:18:30 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|  PF08239   | 3219         |  PF01510   | 4782         |  PF00246   | 948          |\n",
      "|  PF06347   | 972          |            |              |            |              |\n",
      "|   total    | 9921         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/06 05:18:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(224,), max_size=300, sample_style='choice'), RandomFlip(horizontal=False, vertical=True)]\n",
      "\u001b[32m[12/06 05:18:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/06 05:18:30 d2.data.common]: \u001b[0mSerializing 9921 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/06 05:18:31 d2.data.common]: \u001b[0mSerialized dataset takes 2.74 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (36, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (36,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/06 05:18:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[12/06 05:18:35 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 134, in train\n",
      "    self.run_step()\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/defaults.py\", line 423, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 222, in run_step\n",
      "    data = next(self._data_loader_iter)\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/common.py\", line 179, in __iter__\n",
      "    for d in self.dataset:\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1085, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/_utils.py\", line 428, in reraise\n",
      "    raise self.exc_type(msg)\n",
      "detectron2.data.detection_utils.SizeMismatchError: Caught SizeMismatchError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/common.py\", line 43, in __getitem__\n",
      "    data = self._map_func(self._dataset[cur_idx])\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/utils/serialize.py\", line 23, in __call__\n",
      "    return self._obj(*args, **kwargs)\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/dataset_mapper.py\", line 126, in __call__\n",
      "    utils.check_image_size(dataset_dict, image)\n",
      "  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/detection_utils.py\", line 200, in check_image_size\n",
      "    expected_wh,\n",
      "detectron2.data.detection_utils.SizeMismatchError: Mismatched (W,H) for image /home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_X7F613_9RHOB_PF08239_SH3_3.png, got (220, 224), expect (300, 224)\n",
      "\n",
      "\u001b[32m[12/06 05:18:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n",
      "\u001b[32m[12/06 05:18:35 d2.utils.events]: \u001b[0m iter: 0    lr: N/A  max_mem: 142M\n"
     ]
    },
    {
     "ename": "SizeMismatchError",
     "evalue": "Caught SizeMismatchError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/common.py\", line 43, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/utils/serialize.py\", line 23, in __call__\n    return self._obj(*args, **kwargs)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/dataset_mapper.py\", line 126, in __call__\n    utils.check_image_size(dataset_dict, image)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/detection_utils.py\", line 200, in check_image_size\n    expected_wh,\ndetectron2.data.detection_utils.SizeMismatchError: Mismatched (W,H) for image /home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_X7F613_9RHOB_PF08239_SH3_3.png, got (220, 224), expect (300, 224)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSizeMismatchError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d879f467de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \"\"\"\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mdata_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/common.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mbucket_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSizeMismatchError\u001b[0m: Caught SizeMismatchError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/common.py\", line 43, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/utils/serialize.py\", line 23, in __call__\n    return self._obj(*args, **kwargs)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/dataset_mapper.py\", line 126, in __call__\n    utils.check_image_size(dataset_dict, image)\n  File \"/home/satish27may/anaconda3/envs/detectron2/lib/python3.7/site-packages/detectron2/data/detection_utils.py\", line 200, in check_image_size\n    expected_wh,\ndetectron2.data.detection_utils.SizeMismatchError: Mismatched (W,H) for image /home/satish27may/ProteinDomainDetection/data/PfamData/None_images/img_X7F613_9RHOB_PF08239_SH3_3.png, got (220, 224), expect (300, 224)\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################################################################\n",
    "# train model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = (\"valid\",)\n",
    "#cfg.MODEL.PIXEL_MEAN = data_mean\n",
    "#cfg.MODEL.PIXEL_STD = data_std\n",
    "cfg.INPUT.RANDOM_FLIP = \"vertical\"\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (img_h,)\n",
    "cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "# Maximum size of the side of the image during training\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = img_w\n",
    "# Size of the smallest side of the image during testing. Set to zero to disable resize in testing.\n",
    "cfg.INPUT.MIN_SIZE_TEST = img_h\n",
    "# Maximum size of the side of the image during testing\n",
    "cfg.INPUT.MAX_SIZE_TEST = img_w\n",
    "\n",
    "\n",
    "cfg.TEST.AUG.FLIP = False\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")  \n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "# cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = len(classes)\n",
    "\n",
    "\n",
    "# exp configs\n",
    "# cfg.MODEL.FPN.IN_FEATURES = [\"res3\", \"res4\", \"res5\"] didint work\n",
    "\n",
    "\n",
    "cfg.OUTPUT_DIR =str(model_dir)\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# evaluate model\n",
    "evaluator = COCOEvaluator(\"valid\", (\"bbox\",), False, output_dir=cfg.OUTPUT_DIR )\n",
    "val_loader = build_detection_test_loader(cfg, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/05 09:18:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(224, 224), max_size=300, sample_style='choice')]\n",
      "\u001b[32m[12/05 09:18:09 d2.data.common]: \u001b[0mSerializing 4251 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/05 09:18:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.17 MiB\n",
      "\u001b[32m[12/05 09:18:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(224, 224), max_size=300, sample_style='choice')]\n",
      "\u001b[32m[12/05 09:18:10 d2.data.common]: \u001b[0mSerializing 4251 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/05 09:18:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.17 MiB\n",
      "\u001b[32m[12/05 09:18:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 4251 images\n",
      "\u001b[32m[12/05 09:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/4251. 0.0634 s / img. ETA=0:04:34\n",
      "\u001b[32m[12/05 09:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 96/4251. 0.0581 s / img. ETA=0:04:06\n",
      "\u001b[32m[12/05 09:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 181/4251. 0.0579 s / img. ETA=0:04:00\n",
      "\u001b[32m[12/05 09:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 266/4251. 0.0578 s / img. ETA=0:03:55\n",
      "\u001b[32m[12/05 09:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 351/4251. 0.0578 s / img. ETA=0:03:50\n",
      "\u001b[32m[12/05 09:18:36 d2.evaluation.evaluator]: \u001b[0mInference done 436/4251. 0.0578 s / img. ETA=0:03:45\n",
      "\u001b[32m[12/05 09:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 521/4251. 0.0578 s / img. ETA=0:03:40\n",
      "\u001b[32m[12/05 09:18:46 d2.evaluation.evaluator]: \u001b[0mInference done 606/4251. 0.0578 s / img. ETA=0:03:35\n",
      "\u001b[32m[12/05 09:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 691/4251. 0.0578 s / img. ETA=0:03:30\n",
      "\u001b[32m[12/05 09:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 776/4251. 0.0578 s / img. ETA=0:03:25\n",
      "\u001b[32m[12/05 09:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 861/4251. 0.0578 s / img. ETA=0:03:20\n",
      "\u001b[32m[12/05 09:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 946/4251. 0.0578 s / img. ETA=0:03:15\n",
      "\u001b[32m[12/05 09:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 1031/4251. 0.0578 s / img. ETA=0:03:10\n",
      "\u001b[32m[12/05 09:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 1116/4251. 0.0578 s / img. ETA=0:03:05\n",
      "\u001b[32m[12/05 09:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 1201/4251. 0.0578 s / img. ETA=0:03:00\n",
      "\u001b[32m[12/05 09:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 1286/4251. 0.0578 s / img. ETA=0:02:55\n",
      "\u001b[32m[12/05 09:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 1371/4251. 0.0578 s / img. ETA=0:02:50\n",
      "\u001b[32m[12/05 09:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 1456/4251. 0.0578 s / img. ETA=0:02:45\n",
      "\u001b[32m[12/05 09:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 1541/4251. 0.0578 s / img. ETA=0:02:40\n",
      "\u001b[32m[12/05 09:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 1626/4251. 0.0578 s / img. ETA=0:02:35\n",
      "\u001b[32m[12/05 09:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 1711/4251. 0.0578 s / img. ETA=0:02:30\n",
      "\u001b[32m[12/05 09:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 1796/4251. 0.0578 s / img. ETA=0:02:25\n",
      "\u001b[32m[12/05 09:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 1881/4251. 0.0578 s / img. ETA=0:02:20\n",
      "\u001b[32m[12/05 09:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 1966/4251. 0.0578 s / img. ETA=0:02:14\n",
      "\u001b[32m[12/05 09:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 2051/4251. 0.0577 s / img. ETA=0:02:09\n",
      "\u001b[32m[12/05 09:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 2136/4251. 0.0577 s / img. ETA=0:02:04\n",
      "\u001b[32m[12/05 09:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 2221/4251. 0.0577 s / img. ETA=0:01:59\n",
      "\u001b[32m[12/05 09:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 2306/4251. 0.0577 s / img. ETA=0:01:54\n",
      "\u001b[32m[12/05 09:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 2391/4251. 0.0577 s / img. ETA=0:01:49\n",
      "\u001b[32m[12/05 09:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 2476/4251. 0.0577 s / img. ETA=0:01:44\n",
      "\u001b[32m[12/05 09:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 2561/4251. 0.0577 s / img. ETA=0:01:39\n",
      "\u001b[32m[12/05 09:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 2646/4251. 0.0577 s / img. ETA=0:01:34\n",
      "\u001b[32m[12/05 09:20:51 d2.evaluation.evaluator]: \u001b[0mInference done 2731/4251. 0.0577 s / img. ETA=0:01:29\n",
      "\u001b[32m[12/05 09:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 2816/4251. 0.0577 s / img. ETA=0:01:24\n",
      "\u001b[32m[12/05 09:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 2901/4251. 0.0577 s / img. ETA=0:01:19\n",
      "\u001b[32m[12/05 09:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 2986/4251. 0.0577 s / img. ETA=0:01:14\n",
      "\u001b[32m[12/05 09:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 3071/4251. 0.0577 s / img. ETA=0:01:09\n",
      "\u001b[32m[12/05 09:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 3156/4251. 0.0577 s / img. ETA=0:01:04\n",
      "\u001b[32m[12/05 09:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 3241/4251. 0.0577 s / img. ETA=0:00:59\n",
      "\u001b[32m[12/05 09:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 3326/4251. 0.0577 s / img. ETA=0:00:54\n",
      "\u001b[32m[12/05 09:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 3411/4251. 0.0577 s / img. ETA=0:00:49\n",
      "\u001b[32m[12/05 09:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 3496/4251. 0.0577 s / img. ETA=0:00:44\n",
      "\u001b[32m[12/05 09:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 3582/4251. 0.0577 s / img. ETA=0:00:39\n",
      "\u001b[32m[12/05 09:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 3667/4251. 0.0577 s / img. ETA=0:00:34\n",
      "\u001b[32m[12/05 09:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 3752/4251. 0.0577 s / img. ETA=0:00:29\n",
      "\u001b[32m[12/05 09:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 3837/4251. 0.0577 s / img. ETA=0:00:24\n",
      "\u001b[32m[12/05 09:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 3922/4251. 0.0577 s / img. ETA=0:00:19\n",
      "\u001b[32m[12/05 09:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 4007/4251. 0.0577 s / img. ETA=0:00:14\n",
      "\u001b[32m[12/05 09:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 4092/4251. 0.0577 s / img. ETA=0:00:09\n",
      "\u001b[32m[12/05 09:22:17 d2.evaluation.evaluator]: \u001b[0mInference done 4177/4251. 0.0577 s / img. ETA=0:00:04\n",
      "\u001b[32m[12/05 09:22:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:10.732404 (0.059051 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/05 09:22:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:04 (0.057696 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/05 09:22:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/05 09:22:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/satish27may/ProteinDomainDetection/models/seq_len_0-300_and_num_samples_1000-10000_model/coco_instances_results.json\n",
      "\u001b[32m[12/05 09:22:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 1.61 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.41 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 18.891 | 30.146 | 19.733 |  nan  | 0.145 | 18.920 |\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP    |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| PF08239    | 18.686 | PF01510    | 45.837 | PF00246    | 8.437 |\n",
      "| PF06347    | 2.602  |            |        |            |       |\n",
      "\u001b[32m[12/05 09:22:25 d2.engine.defaults]: \u001b[0mEvaluation results for valid in csv format:\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/05 09:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: 18.8905,30.1457,19.7327,nan,0.1446,18.9199\n",
      "OrderedDict([('bbox', {'AP': 18.890516199874263, 'AP50': 30.14572377951327, 'AP75': 19.73268519287744, 'APs': nan, 'APm': 0.14462331093769515, 'APl': 18.919920052309198, 'AP-PF08239': 18.685715468927235, 'AP-PF01510': 45.83710918579928, 'AP-PF00246': 8.436770861221882, 'AP-PF06347': 2.6024692835486545})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"valid\", (\"bbox\",), False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"valid\")\n",
    "print(trainer.test(cfg, trainer.model, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(bucket_df[bucket_df['Class']=='PF06347']['Sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
